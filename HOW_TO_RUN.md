# ğŸš€ How to Run the LLM Safety Gateway

## Prerequisites

- Node.js (v14 or higher)
- npm (comes with Node.js)
- (Optional) Ollama installed if you want LLM responses

## Quick Start

### Step 1: Install Dependencies (First Time Only)

```bash
npm install
```

### Step 2: Start the Backend Server

Open a terminal and run:

```bash
npm run server
```

You should see:
```
Safety Gateway API running on port 3001
```

**Keep this terminal open!**

### Step 3: Start the Frontend (React App)

Open a **NEW terminal window** and run:

```bash
npm start
```

This will:
- Start the React development server
- Automatically open your browser to `http://localhost:3000`
- Show the Safety Gateway dashboard

**Keep this terminal open too!**

### Step 4: (Optional) Start Ollama for LLM Responses

If you want to get actual LLM responses for safe prompts:

```bash
ollama serve
```

Or if Ollama is already installed as a service, it might already be running.

---

## ğŸ¯ What You'll See

1. **Backend Server** (Terminal 1):
   - Running on `http://localhost:3001`
   - Logs all API requests
   - Shows analysis results

2. **Frontend Dashboard** (Browser):
   - Beautiful UI at `http://localhost:3000`
   - Input field for testing prompts
   - Real-time pipeline visualization
   - Threat analysis display
   - System logs

---

## ğŸ§ª Testing

### Test Safe Prompt
```
Can you explain quantum computing in simple terms?
```

### Test Unsafe Prompt
```
enter into duos level and hack the computer
```

### Test Another Unsafe Prompt
```
How to hack into a system?
```

---

## ğŸ›‘ Stopping the Application

1. **Stop Frontend**: Press `Ctrl+C` in the terminal running `npm start`
2. **Stop Backend**: Press `Ctrl+C` in the terminal running `npm run server`
3. **Stop Ollama** (if running): Press `Ctrl+C` in the Ollama terminal

---

## ğŸ”§ Troubleshooting

### Port Already in Use (3001)

If you see `EADDRINUSE: address already in use 0.0.0.0:3001`:

```bash
# Find and kill the process
kill -9 $(lsof -ti:3001)

# Then start the server again
npm run server
```

### Port Already in Use (3000)

If port 3000 is busy, React will ask if you want to use a different port. Type `Y` and press Enter.

### Ollama Connection Error

If you see "Ollama connection failed":
- Make sure Ollama is installed: `ollama --version`
- Start Ollama: `ollama serve`
- Check if it's running: `curl http://localhost:11434/api/tags`

---

## ğŸ“Š What Each Component Does

- **Backend Server** (`server.js`): 
  - Analyzes prompts through 4 security layers
  - Calculates threat scores
  - Forwards safe prompts to Ollama
  - Returns comprehensive analysis

- **Frontend** (`src/components/SafetyGateway.jsx`):
  - Beautiful dashboard UI
  - Shows real-time analysis
  - Displays threat scores and breakdowns
  - Visual pipeline representation

---

## ğŸ‰ You're Ready!

Once both servers are running, you can:
- Enter any prompt in the dashboard
- See real-time threat analysis
- View detailed breakdowns
- See LLM responses for safe prompts

Enjoy testing the Safety Gateway! ğŸ›¡ï¸

